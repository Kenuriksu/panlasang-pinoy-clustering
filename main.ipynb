{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingredient-Based Clustering of Pinoy Dishes\n",
    "\n",
    "The ambition is to identify clusters of Filipino dishes based on their ingredients. The results can be used to define the most common ingredients of a Filipino pantry. This project leverages techniques from data mining, natural language processing, and unsupervised learning. The dataset is a collection of Filipino recipes from various online recipe websites. The dataset contains the name, ingredients, and instructions of the recipes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def load_recipes(path=\"data/recipes\"):\n",
    "    \"\"\"Combines all recipe data into a single list.\"\"\"\n",
    "    files = [file for file in os.listdir(path)]\n",
    "\n",
    "    recipes = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        with open(file_path, encoding=\"utf-8\") as f:\n",
    "            recipe_data = json.load(f)\n",
    "            recipes.extend(recipe_data)\n",
    "\n",
    "    return recipes\n",
    "\n",
    "\n",
    "recipes = load_recipes()\n",
    "recipes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "recipe_df = pd.DataFrame(recipes)\n",
    "recipe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_ingredient_count_distribution(ingredient_series, figsize=(8, 3)):\n",
    "    \"\"\"Plots the distribution of the number of ingredients in recipes.\"\"\"\n",
    "    counts = ingredient_series.dropna().apply(len)\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.histplot(counts, kde=True, binwidth=1)\n",
    "    plt.title(f\"Number of ingredients in {len(counts)} recipes\")\n",
    "    plt.xlabel(\"Number of ingredients\")\n",
    "    plt.ylabel(\"Number of recipes\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_common_ingredients(\n",
    "    ingredient_series, n=30, most_common=True, figsize=(8, 7)\n",
    "):\n",
    "    \"\"\"Plots the most or least common ingredients.\"\"\"\n",
    "    all_ingredients = ingredient_series.dropna().explode()\n",
    "    ingredient_counts = all_ingredients.value_counts()\n",
    "\n",
    "    if most_common:\n",
    "        top_n_ingredients = ingredient_counts.head(n)\n",
    "    else:\n",
    "        top_n_ingredients = ingredient_counts.tail(n)\n",
    "\n",
    "    ylabels = [\n",
    "        f\"{i[:20]:>20}{'...' if len(i) > 20 else ''}\"\n",
    "        for i in top_n_ingredients.index\n",
    "    ]\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.barplot(x=top_n_ingredients.values, y=ylabels)\n",
    "    indicator = \"Most\" if most_common else \"Least\"\n",
    "    plt.title(f\"Top {n} {indicator} Common Ingredients\")\n",
    "    plt.xlabel(\"Number of Recipes\")\n",
    "    plt.ylabel(\"Ingredient\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_ingredient_count_distribution(recipe_df.ingredients)\n",
    "plot_common_ingredients(recipe_df.ingredients, n=30, most_common=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove recipes with no ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df = recipe_df.dropna(subset=[\"ingredients\"])\n",
    "recipe_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean ingredient format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def remove_parentheses(ingredient):\n",
    "    \"\"\"Removes parentheses and content from ingredient strings.\"\"\"\n",
    "    return re.sub(r\" ?\\([^)]+\\)\", \"\", ingredient)\n",
    "\n",
    "\n",
    "def select_first_option(ingredient):\n",
    "    \"\"\"Selects the first option in a string with multiple options.\"\"\"\n",
    "    return ingredient.split(\" or \")[0]\n",
    "\n",
    "\n",
    "def clean_ingredient(ingredient):\n",
    "    \"\"\"Cleans an ingredient string.\"\"\"\n",
    "    ingredient = remove_parentheses(ingredient)\n",
    "    ingredient = select_first_option(ingredient)\n",
    "    return ingredient.lower().strip()\n",
    "\n",
    "\n",
    "recipe_df[\"clean_ingredients\"] = recipe_df.ingredients.progress_apply(\n",
    "    lambda x: [clean_ingredient(i) for i in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize words and remove non-ingredient words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n",
    "def correct_noun_pos_tags(token):\n",
    "    \"\"\"Corrects the POS tags of specific tokens.\"\"\"\n",
    "    outliers = [\"cauliflower\", \"baking\"]\n",
    "    if token.text in outliers:\n",
    "        token.pos_ = \"NOUN\"\n",
    "    return token\n",
    "\n",
    "\n",
    "def lemmatize_nouns(ingredient):\n",
    "    \"\"\"Lemmatizes nouns in an ingredient string.\"\"\"\n",
    "    doc = nlp(ingredient)\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        token = correct_noun_pos_tags(token)\n",
    "        if (\n",
    "            token.is_alpha\n",
    "            and not token.is_stop\n",
    "            and token.pos_ in [\"NOUN\", \"PROPN\"]\n",
    "        ):\n",
    "            lemmas.append(token.lemma_)\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "\n",
    "recipe_df[\"lemmatized\"] = recipe_df.clean_ingredients.progress_apply(\n",
    "    lambda x: [lemmatized for i in x if (lemmatized := lemmatize_nouns(i))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words related to culinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/culinary_stopwords.txt\") as file:\n",
    "    culinary_stopwords = file.read().splitlines()\n",
    "\n",
    "\n",
    "def filter_stopwords(text, stopwords=culinary_stopwords):\n",
    "    \"\"\"Filter out stopwords from a string.\"\"\"\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        if word not in stopwords:\n",
    "            words.append(word)\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "recipe_df[\"filtered\"] = recipe_df.lemmatized.progress_apply(\n",
    "    lambda x: [filtered for i in x if (filtered := filter_stopwords(i))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate terms in ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(text):\n",
    "    \"\"\"Remove duplicate terms while preserving order.\"\"\"\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for word in text.split():\n",
    "        if word not in seen:\n",
    "            unique.append(word)\n",
    "            seen.add(word)\n",
    "    return \" \".join(unique)\n",
    "\n",
    "\n",
    "recipe_df[\"unique\"] = recipe_df.filtered.progress_apply(\n",
    "    lambda x: [unique for i in x if (unique := remove_duplicates(i))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace ingredients with common names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/culinary_synonyms.json\") as file:\n",
    "    synonyms = json.load(file)\n",
    "\n",
    "\n",
    "def replace_words_with_standard_name(ingredient):\n",
    "    \"\"\"Replace words in an ingredient with standard names.\"\"\"\n",
    "    words = []\n",
    "    for word in ingredient.split():\n",
    "        words.append(synonyms.get(word, word))\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    \"\"\"Remove duplicate terms while preserving order.\"\"\"\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for word in text.split():\n",
    "        if word not in seen:\n",
    "            unique.append(word)\n",
    "            seen.add(word)\n",
    "    return \" \".join(unique)\n",
    "\n",
    "\n",
    "def replace_ingredient_with_standard_name(ingredient):\n",
    "    \"\"\"Replace the entire ingredient with a common name if available.\"\"\"\n",
    "    common_name = replace_words_with_standard_name(ingredient)\n",
    "    unique_name = remove_duplicates(common_name)\n",
    "    return synonyms.get(unique_name, unique_name)\n",
    "\n",
    "\n",
    "recipe_df[\"standardized\"] = recipe_df.filtered.progress_apply(\n",
    "    lambda x: [\n",
    "        common_name\n",
    "        for i in x\n",
    "        if (common_name := replace_ingredient_with_standard_name(i))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break down ingredients into basic components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ingredient_components.json\") as file:\n",
    "    ingredient_components = json.load(file)\n",
    "\n",
    "\n",
    "def break_down_ingredient(ingredient):\n",
    "    \"\"\"Breaks down an ingredient into its components.\"\"\"\n",
    "    components = ingredient_components.get(ingredient, ingredient)\n",
    "    if isinstance(components, str):\n",
    "        return [components]\n",
    "    return components\n",
    "\n",
    "\n",
    "recipe_df[\"components\"] = recipe_df.standardized.progress_apply(\n",
    "    lambda x: [component for i in x for component in break_down_ingredient(i)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = recipe_df.components.explode().unique().astype(str).tolist()\n",
    "ingredients.sort()\n",
    "\n",
    "with open(\"data/cleaned_ingredients.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(ingredients))\n",
    "\n",
    "raise ValueError  # Stop execution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rare ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = recipe_df.components.explode().value_counts()\n",
    "\n",
    "with open(\"data/ingredient_counts.json\", \"w\") as file:\n",
    "    json.dump(counts.to_dict(), file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_INGREDIENT_COUNT = 5\n",
    "\n",
    "rare_ingredients = counts[counts <= MIN_INGREDIENT_COUNT].index\n",
    "\n",
    "\n",
    "def remove_rare_ingredient(ingredient):\n",
    "    \"\"\"Removes rare ingredients from a list.\"\"\"\n",
    "    return ingredient if ingredient not in rare_ingredients else None\n",
    "\n",
    "\n",
    "recipe_df[\"frequent\"] = recipe_df.standardized.apply(\n",
    "    lambda x: [remove_rare_ingredient(i) for i in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ingredient_count_distribution(recipe_df.standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove recipes with too few or too many ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the 3rd quartile minus 1st quartile (75%)\n",
    "MIN_INGREDIENTS_IN_RECIPE = 4\n",
    "MAX_INGREDIENTS_IN_RECIPE = 9\n",
    "\n",
    "counts = recipe_df.common_names.apply(len)\n",
    "recipe_df = recipe_df[\n",
    "    (counts >= MIN_INGREDIENTS_IN_RECIPE)\n",
    "    & (counts <= MAX_INGREDIENTS_IN_RECIPE)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add flavor tags to ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/flavor_map.json\") as file:\n",
    "    flavor_map = json.load(file)\n",
    "\n",
    "\n",
    "def map_ingredient_to_flavor(ingredient):\n",
    "    \"\"\"Maps an ingredient to a flavor.\"\"\"\n",
    "    flavor = flavor_map.get(ingredient, \"\")\n",
    "    if flavor == \"flavorless\":\n",
    "        return ingredient\n",
    "    return f\"{flavor} {ingredient}\"\n",
    "\n",
    "\n",
    "recipe_df[\"with_flavors\"] = recipe_df.common_names.progress_apply(\n",
    "    lambda x: [map_ingredient_to_flavor(i) for i in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "ingredients_as_texts = [\n",
    "    \" \".join(sorted(ingredients))\n",
    "    for ingredients in recipe_df[\"cleaned_ingredients\"]\n",
    "]\n",
    "embeddings = model.encode(\n",
    "    ingredients_as_texts,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "dimensions_to_keep = 2\n",
    "svd = TruncatedSVD(n_components=dimensions_to_keep)\n",
    "reduced_embeddings = svd.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "n_clusters = 7\n",
    "clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage=\"ward\")\n",
    "cluster_labels = clustering.fit_predict(reduced_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_clusters_3d(reduced_embeddings, cluster_labels, recipe_df):\n",
    "    \"\"\"Plots a 3D scatter plot of recipe clusters.\"\"\"\n",
    "\n",
    "    final_df = pd.DataFrame(\n",
    "        {\n",
    "            \"x\": reduced_embeddings[:, 0],\n",
    "            \"y\": reduced_embeddings[:, 1],\n",
    "            # \"z\": reduced_embeddings[:, 2],\n",
    "            \"cluster\": cluster_labels.astype(str),\n",
    "            \"recipe_name\": recipe_df[\"name\"],\n",
    "            \"cleaned_ingredients\": [\n",
    "                \"<br>\".join(ingredients)\n",
    "                for ingredients in recipe_df[\"cleaned_ingredients\"]\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fig = px.scatter(\n",
    "        final_df,\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        # z=\"z\",\n",
    "        color=\"cluster\",\n",
    "        hover_name=\"recipe_name\",\n",
    "        hover_data=[\"cleaned_ingredients\"],\n",
    "        width=800,\n",
    "        height=1000,\n",
    "        color_discrete_sequence=px.colors.qualitative.Bold,\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker=dict(size=5))\n",
    "    fig.update_layout(title=\"Ingredient-Based Clustering of Filipino Dishes\")\n",
    "\n",
    "    unique_clusters = final_df[\"cluster\"].unique()\n",
    "    buttons = [\n",
    "        dict(\n",
    "            label=f\"Cluster {cluster}\",\n",
    "            method=\"update\",\n",
    "            args=[\n",
    "                {\"visible\": [cluster == c for c in unique_clusters]},\n",
    "                {\"title\": f\"Ingredient-Based Clustering - Cluster {cluster}\"},\n",
    "            ],\n",
    "        )\n",
    "        for cluster in unique_clusters\n",
    "    ]\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"buttons\",\n",
    "                direction=\"down\",\n",
    "                buttons=buttons,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_clusters_3d(reduced_embeddings, cluster_labels, reduced_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
